{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee4054c416947fe94dccfe21aedf511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b647825235064109ae4ee1ac476c9a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/63 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3329691388964060948e548ac9769c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "DatasetGenerationError",
     "evalue": "An error occurred while generating the dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\datasets\\builder.py\u001b[0m in \u001b[0;36m_prepare_split_single\u001b[1;34m(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\u001b[0m\n\u001b[0;32m   1869\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1870\u001b[1;33m                         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1871\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mCastError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcast_error\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\datasets\\arrow_writer.py\u001b[0m in \u001b[0;36mwrite_table\u001b[1;34m(self, pa_table, writer_batch_size)\u001b[0m\n\u001b[0;32m    626\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_examples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpa_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyarrow\\ipc.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._CRecordBatchWriter.write_table\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyarrow\\error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fsspec\\implementations\\local.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatasetGenerationError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_596/4010298304.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0myodas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'yodas2_ru000_16k'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'audio'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAudio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mSimpleTextSearcher\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\datasets\\load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[0;32m   2152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2153\u001b[0m     \u001b[1;31m# Download and prepare data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2154\u001b[1;33m     builder_instance.download_and_prepare(\n\u001b[0m\u001b[0;32m   2155\u001b[0m         \u001b[0mdownload_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2156\u001b[0m         \u001b[0mdownload_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\datasets\\builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[1;34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[0;32m    922\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m                         \u001b[0mprepare_split_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"num_proc\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_proc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m                     self._download_and_prepare(\n\u001b[0m\u001b[0;32m    925\u001b[0m                         \u001b[0mdl_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m                         \u001b[0mverification_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverification_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\datasets\\builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[1;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[0;32m    998\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m                 \u001b[1;31m# Prepare split will record examples associated to the split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1000\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mprepare_split_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1001\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1002\u001b[0m                 raise OSError(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\datasets\\builder.py\u001b[0m in \u001b[0;36m_prepare_split\u001b[1;34m(self, split_generator, file_format, num_proc, max_shard_size)\u001b[0m\n\u001b[0;32m   1739\u001b[0m             \u001b[0mjob_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1740\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1741\u001b[1;33m                 for job_id, done, content in self._prepare_split_single(\n\u001b[0m\u001b[0;32m   1742\u001b[0m                     \u001b[0mgen_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgen_kwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0m_prepare_split_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1743\u001b[0m                 ):\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\datasets\\builder.py\u001b[0m in \u001b[0;36m_prepare_split_single\u001b[1;34m(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\u001b[0m\n\u001b[0;32m   1895\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatasetGenerationError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1896\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1897\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mDatasetGenerationError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"An error occurred while generating the dataset\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1899\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mjob_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtotal_num_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_num_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_shards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshard_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDatasetGenerationError\u001b[0m: An error occurred while generating the dataset"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from datasets import load_dataset, Audio\n",
    "\n",
    "yodas = load_dataset('yodas2_ru000_16k').cast_column('audio', Audio(decode=True))['train']\n",
    "\n",
    "class SimpleTextSearcher:\n",
    "    def __init__(self):\n",
    "        self._dict = {}\n",
    "    def add(self, id: str, text: str):\n",
    "        self._dict[id] = text\n",
    "    def find(self, query: str, max_count: int | None = None) -> list[str]:\n",
    "        return [id for id, text in self._dict.items() if query in text][:max_count]\n",
    "\n",
    "searcher = SimpleTextSearcher()\n",
    "for text_file in list(Path('yodas_search/yodas_texts').glob('*.txt'))[:100]:\n",
    "    with open(text_file) as f:\n",
    "        searcher.add(id=int(text_file.stem), text=f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "results_per_tab = 3\n",
    "n_tabs = 20\n",
    "    \n",
    "with gr.Blocks(fill_height=True, theme=gr.themes.Origin()) as demo:\n",
    "    \n",
    "    with gr.Row(equal_height=True):\n",
    "        with gr.Column(scale=3):\n",
    "            query = gr.Textbox(label=\"Query\", autofocus=True)\n",
    "            collected = gr.Textbox(label=\"Collected audios\", lines=4)\n",
    "        transcription = gr.Textbox(label=\"Transcription\", scale=7, lines=9, interactive=False)\n",
    "    \n",
    "    def add_result(query: str, collected: str, id: str) -> gr.Textbox:\n",
    "        new_line = f'{id} (q=\"{query}\")'\n",
    "        return gr.Textbox(value= f'{collected}, {new_line}' if len(collected) else new_line)\n",
    "    \n",
    "    search_result_elements = []\n",
    "    for tab_idx in range(n_tabs):\n",
    "        with gr.Tab(f\"{tab_idx * results_per_tab + 1}-{(tab_idx + 1) * results_per_tab}\"):\n",
    "            for i in range(results_per_tab):\n",
    "                with gr.Row(variant='compact', equal_height=True):\n",
    "                    with gr.Column(scale=1, min_width=0):\n",
    "                        search_result_elements.append(add_button := gr.Button(visible=False, min_width=0))\n",
    "                        search_result_elements.append(result_id := gr.Label(visible=False, min_width=0, container=False))\n",
    "                    search_result_elements.append(gr.Audio(visible=False, scale=15, editable=False, waveform_options=))\n",
    "                    add_button.click(add_result, inputs=[query, collected, result_id], outputs=collected)\n",
    "\n",
    "    debug_log = gr.Textbox(label=\"Debug log\", lines=3, interactive=False)\n",
    "\n",
    "    def search(query: str, debug_log: str) -> list[gr.Button]:\n",
    "\n",
    "        found_ids = searcher.find(query, max_count=results_per_tab * n_tabs)\n",
    "        debug_log += f'Search query: \"{query}\\n\", found {len(found_ids)} results:'\n",
    "\n",
    "        returned_elements = []\n",
    "        for i in range(results_per_tab * n_tabs):\n",
    "            if i < len(found_ids):\n",
    "                id = found_ids[i]\n",
    "                sample = yodas[id]\n",
    "                youtube_id = sample['video_id']\n",
    "                audio_path = sample['audio']['path']\n",
    "                audio_len = len(yodas[0]['audio']['array']) / yodas[0]['audio']['sampling_rate']\n",
    "                filesize = Path(audio_path).stat().st_size\n",
    "                debug_log += (\n",
    "                    f'id={id} | {audio_len:.0f} sec | {filesize / 1024**2:.0f} MB'\n",
    "                    f' | https://www.youtube.com/watch?v={youtube_id}'\n",
    "                    '\\n'\n",
    "                )\n",
    "                returned_elements += [\n",
    "                    gr.Button(visible=True, value=\"Add\"),\n",
    "                    gr.Label(visible=False, value=id),  # to save audio id\n",
    "                    gr.Audio(visible=True, value=audio_path, label=f'id {id}, youtube_id {youtube_id}'),\n",
    "                ]\n",
    "            else:\n",
    "                returned_elements += [\n",
    "                    gr.Button(visible=False),\n",
    "                    gr.Label(visible=False),\n",
    "                    gr.Audio(visible=False),\n",
    "                ]\n",
    "\n",
    "        return returned_elements + [debug_log]\n",
    "    \n",
    "    query.submit(search, inputs=[query, debug_log], outputs=search_result_elements + [debug_log])\n",
    "\n",
    "demo.launch(share=True, allowed_paths=['/home/oleg/.cache/huggingface'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
